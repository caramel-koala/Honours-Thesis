This chapter concludes the thesis by summarising the work done, presenting the achievements of the research and suggesting future work based on the results obtained.
\section{Thesis Summary}
An improvement to the current best model for generating tessellations for correcting \gls{dd} effects was presented in this thesis. We began by first researching what direction dependant effects are and why they need to be corrected for. Tessellation models, mainly the Voronoi tessellation, were researched as well as different methods of implementing Voronoi tessellations and clustering algorithms. Lastly parallel paradigms, GPUs, the GPU architecture and CUDA, the NVIDIA GPU programming language, were analysed for their potential contribution to the proposed research.
\\
\\
The algorithm that would be used to generate an improved tessellation was defined. It was decided that, optimally, the tessellation would occur in two stages. The first stage would be a Voronoi tessellation which was generated using most or all of the data sources as cell centres. For this the divide-and-conquer algorithm was chosen for its efficient $O(n\log n)$ computation time and also for its potential to be converted to a parallel algorithm. The second part of the tessellation generation used the error of the cells to find and execute optimal cell merges to decrease the number of cells while increasing the overall error in a minimal way. The cell merge algorithm iteratively cycles through finding the best merge to execute by testing the merge of each cell with its neighbour and, once found, executing the best merge until the maximum error threshold is reached.
\\
\\
The cell merge process within the main algorithm was ported to execute as a parallel process on the GPU. Numba's CUDA JIT compiler was used to convert specific Python commands and functions to CUDA code for execution on the GPU. The conversion of the data, from a large relational network of pointers to a set of multidimensional arrays of a fixed size was discussed. The parallelisation of the merge testing algorithm was explained as well as executing the merge on both the CPU and the GPU. Issues with the GPU execution due to differences in floating point calculations were noted.
\\
\\
Results from testing the algorithms were analysed. It was found that for most tessellations for a given data set, the cell merge algorithm had a lower error than that obtained when using a standard Voronoi tessellation. For a very small number of cells per source, $\leq 3\%$, the Voronoi is more effective with smaller errors. For the GPU implementation of the cell merge, it was found that the speed-up of the algorithm varied with the number of sources. For a tessellation with 10 sources, it was found that the GPU execution was slower than that of the sequential algorithm while, for 1000 sources, the speed-up was 39.96x. The cause of the change in the speed-up was found to be the overhead of transferring data to the GPU. For a smaller set of sources, this cost is relatively high but increases at a much lower rate than that of the merge execution itself, which is the main process being sped-up.